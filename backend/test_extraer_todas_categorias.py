#!/usr/bin/env python3
"""
Script para extraer TODAS las categorÃ­as de Carrefour y DÃ­a recursivamente
Similar a cÃ³mo se hizo con La Reina (212) y La Gallega (136)
"""

import json
from typing import List, Dict, Set

def extraer_categorias_recursivo(nodo: Dict, nivel: int = 0) -> List[Dict]:
    """
    Extrae todas las categorÃ­as de un Ã¡rbol de forma recursiva
    
    Retorna lista de dicts con:
    - id: ID de categorÃ­a
    - name: Nombre de categorÃ­a
    - url: URL de categorÃ­a
    - nivel: Nivel en el Ã¡rbol (0=raÃ­z, 1=subcategorÃ­a, etc.)
    """
    categorias = []
    
    # Agregar categorÃ­a actual
    categorias.append({
        'id': nodo['id'],
        'name': nodo['name'],
        'url': nodo.get('url', ''),
        'nivel': nivel
    })
    
    # Procesar hijos recursivamente
    if 'children' in nodo and nodo['children']:
        for hijo in nodo['children']:
            categorias.extend(extraer_categorias_recursivo(hijo, nivel + 1))
    
    return categorias


def procesar_carrefour():
    """Procesa Ã¡rbol de categorÃ­as de Carrefour"""
    
    print("=" * 80)
    print("ğŸ›’ CARREFOUR - Extrayendo todas las categorÃ­as")
    print("=" * 80)
    
    with open('carrefour_categorias_response.json', 'r', encoding='utf-8') as f:
        arbol = json.load(f)
    
    todas_categorias = []
    
    # Procesar cada categorÃ­a raÃ­z
    for nodo_raiz in arbol:
        categorias_rama = extraer_categorias_recursivo(nodo_raiz)
        todas_categorias.extend(categorias_rama)
    
    # EstadÃ­sticas por nivel
    categorias_por_nivel = {}
    for cat in todas_categorias:
        nivel = cat['nivel']
        if nivel not in categorias_por_nivel:
            categorias_por_nivel[nivel] = []
        categorias_por_nivel[nivel].append(cat)
    
    print(f"\nâœ… Total categorÃ­as: {len(todas_categorias)}")
    print(f"\nğŸ“Š DistribuciÃ³n por nivel:")
    for nivel in sorted(categorias_por_nivel.keys()):
        cats = categorias_por_nivel[nivel]
        print(f"   Nivel {nivel}: {len(cats)} categorÃ­as")
        if len(cats) <= 20:  # Mostrar solo si no son muchas
            for cat in cats[:10]:
                print(f"      - {cat['name']} (ID: {cat['id']})")
            if len(cats) > 10:
                print(f"      ... y {len(cats) - 10} mÃ¡s")
    
    # Guardar lista completa
    with open('carrefour_categorias_completas.json', 'w', encoding='utf-8') as f:
        json.dump(todas_categorias, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ Guardado en carrefour_categorias_completas.json")
    
    # Generar cÃ³digo Python para scraper (solo IDs de categorÃ­as Ãºtiles para comida)
    categorias_comida = [cat for cat in todas_categorias if any(
        keyword in cat['name'].lower() 
        for keyword in ['almacÃ©n', 'almacen', 'bebida', 'lÃ¡cteo', 'lacteo', 'fresco', 
                       'carne', 'verdura', 'fruta', 'panaderÃ­a', 'panaderia',
                       'congelado', 'despensa', 'conserva', 'snack', 'golosina',
                       'desayuno', 'infusiÃ³n', 'infusion', 'aceite', 'condimento']
    )]
    
    print(f"\nğŸ½ï¸ CategorÃ­as relacionadas con comida: {len(categorias_comida)}")
    
    # Generar lista de IDs para el scraper
    ids_categorias = sorted(set(cat['id'] for cat in todas_categorias))
    print(f"\nğŸ“‹ IDs Ãºnicos: {len(ids_categorias)}")
    
    # CÃ³digo Python para copiar al scraper
    print(f"\n" + "="*80)
    print("ğŸ“ CÃ“DIGO PARA scraper_carrefour.py:")
    print("="*80)
    print(f"# Total: {len(ids_categorias)} categorÃ­as")
    print("CATEGORIAS = [")
    for i in range(0, len(ids_categorias), 10):
        batch = ids_categorias[i:i+10]
        print("    " + ", ".join(str(id) for id in batch) + ",")
    print("]")
    
    return todas_categorias, ids_categorias


def procesar_dia():
    """Procesa Ã¡rbol de categorÃ­as de DÃ­a"""
    
    print("\n\n")
    print("=" * 80)
    print("ğŸ›’ DÃA % - Extrayendo todas las categorÃ­as")
    print("=" * 80)
    
    with open('dia_categorias_response.json', 'r', encoding='utf-8') as f:
        arbol = json.load(f)
    
    todas_categorias = []
    
    # Procesar cada categorÃ­a raÃ­z
    for nodo_raiz in arbol:
        categorias_rama = extraer_categorias_recursivo(nodo_raiz)
        todas_categorias.extend(categorias_rama)
    
    # EstadÃ­sticas por nivel
    categorias_por_nivel = {}
    for cat in todas_categorias:
        nivel = cat['nivel']
        if nivel not in categorias_por_nivel:
            categorias_por_nivel[nivel] = []
        categorias_por_nivel[nivel].append(cat)
    
    print(f"\nâœ… Total categorÃ­as: {len(todas_categorias)}")
    print(f"\nğŸ“Š DistribuciÃ³n por nivel:")
    for nivel in sorted(categorias_por_nivel.keys()):
        cats = categorias_por_nivel[nivel]
        print(f"   Nivel {nivel}: {len(cats)} categorÃ­as")
        if len(cats) <= 20:
            for cat in cats[:10]:
                print(f"      - {cat['name']} (ID: {cat['id']})")
            if len(cats) > 10:
                print(f"      ... y {len(cats) - 10} mÃ¡s")
    
    # Guardar lista completa
    with open('dia_categorias_completas.json', 'w', encoding='utf-8') as f:
        json.dump(todas_categorias, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ Guardado en dia_categorias_completas.json")
    
    # Generar lista de IDs
    ids_categorias = sorted(set(cat['id'] for cat in todas_categorias))
    print(f"\nğŸ“‹ IDs Ãºnicos: {len(ids_categorias)}")
    
    # CÃ³digo Python para scraper
    print(f"\n" + "="*80)
    print("ğŸ“ CÃ“DIGO PARA scraper_dia.py:")
    print("="*80)
    print(f"# Total: {len(ids_categorias)} categorÃ­as")
    print("CATEGORIAS = [")
    for i in range(0, len(ids_categorias), 10):
        batch = ids_categorias[i:i+10]
        print("    " + ", ".join(str(id) for id in batch) + ",")
    print("]")
    
    return todas_categorias, ids_categorias


if __name__ == "__main__":
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘           EXTRACCIÃ“N COMPLETA DE CATEGORÃAS - CARREFOUR Y DÃA             â•‘")
    print("â•‘                                                                            â•‘")
    print("â•‘  Similar a La Reina (212 cats) y La Gallega (136 cats)                   â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # Procesar Carrefour
    carrefour_cats, carrefour_ids = procesar_carrefour()
    
    # Procesar DÃ­a
    dia_cats, dia_ids = procesar_dia()
    
    # Resumen final
    print("\n\n")
    print("=" * 80)
    print("ğŸ“Š RESUMEN FINAL")
    print("=" * 80)
    print(f"ğŸ›’ Carrefour: {len(carrefour_cats)} categorÃ­as totales, {len(carrefour_ids)} IDs Ãºnicos")
    print(f"ğŸ›’ DÃ­a %:     {len(dia_cats)} categorÃ­as totales, {len(dia_ids)} IDs Ãºnicos")
    print(f"ğŸ›’ La Reina:  212 categorÃ­as (HTML scraping)")
    print(f"ğŸ›’ La Gallega: 136 categorÃ­as (HTML scraping)")
    print(f"\nâœ… TOTAL: {len(carrefour_cats) + len(dia_cats) + 212 + 136} categorÃ­as mapeadas en los 4 supermercados")
    print("=" * 80)
    print("\n")
