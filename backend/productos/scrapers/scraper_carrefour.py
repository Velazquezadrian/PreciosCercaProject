# Scraper para Carrefour usando API VTEX con 148 categor√≠as
from .base_scraper import BaseScraper
from typing import List, Dict
import json
import sys
import os

# Importar cache_manager desde backend/
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
from cache_manager import cache_manager

class ScraperCarrefour(BaseScraper):
    def __init__(self):
        # VTEX API endpoint para b√∫squedas
        super().__init__(
            base_url="https://www.carrefour.com.ar",
            supermercado_nombre="Carrefour"
        )
        self.api_search_url = "https://www.carrefour.com.ar/api/catalog_system/pub/products/search"
        self._precargando = False  # Flag para evitar recursi√≥n infinita
        
        # 148 categor√≠as extra√≠das del √°rbol completo de Carrefour
        # Similar a La Reina (212 cats) y La Gallega (136 cats)
        self.categorias = [
            1, 3, 4, 7, 11, 15, 20, 25, 31, 42,
            48, 56, 62, 71, 72, 88, 138, 148, 157, 161,
            162, 168, 172, 176, 183, 190, 195, 199, 206, 208,
            214, 222, 223, 229, 232, 233, 238, 242, 246, 250,
            255, 256, 257, 262, 266, 273, 277, 283, 286, 290,
            291, 292, 293, 299, 302, 303, 304, 305, 306, 307,
            308, 309, 310, 318, 321, 322, 323, 324, 326, 327,
            329, 330, 331, 332, 333, 334, 336, 337, 340, 344,
            345, 346, 347, 348, 349, 350, 352, 356, 358, 359,
            360, 367, 376, 377, 384, 385, 386, 387, 390, 394,
            402, 403, 412, 418, 422, 427, 435, 438, 443, 444,
            445, 451, 452, 453, 458, 462, 466, 467, 468, 469,
            470, 471, 472, 473, 474, 475, 498, 499, 514, 525,
            564, 600, 605, 606, 607, 608, 635, 636, 637, 640,
            650, 658, 665, 666, 667, 668, 669, 686,
        ]
    
    def _auto_precargar(self):
        """Precarga autom√°tica usando el m√©todo buscar_productos() que YA FUNCIONA"""
        print("")
        print("="*80)
        print("üöÄ AUTOPRECARGA: Llenando cach√© de Carrefour con b√∫squedas reales...")
        print("="*80)
        print("‚ö†Ô∏è  Este proceso tarda 3-5 minutos (usa b√∫squedas normales que funcionan)")
        print("‚ö†Ô∏è  El cach√© se llena progresivamente, no necesita todo desde el inicio")
        print("")
        
        print(f"üìä Buscando productos comunes para llenar cach√© inicial...")
        print("")
        
        total_agregados = 0
        from time import sleep
        
        # Palabras clave que la gente realmente busca
        queries = [
            'leche', 'pan', 'yogur', 'queso', 'manteca', 'dulce de leche',
            'aceite', 'arroz', 'fideos', 'harina', 'azucar', 'sal',
            'cafe', 'te', 'mate', 'yerba', 'galletas', 'cerveza',
            'agua', 'gaseosa', 'jugo', 'vino', 'carne', 'pollo'
        ]
        
        for idx, palabra in enumerate(queries, 1):
            try:
                print(f"[{idx}/{len(queries)}] Buscando '{palabra}'...", end=" ", flush=True)
                
                # Usar el m√©todo buscar_productos() que YA FUNCIONA
                # Este m√©todo maneja la API correctamente y ya cachea autom√°ticamente
                productos = self.buscar_productos(palabra)
                
                if productos:
                    # Los productos ya est√°n cacheados por buscar_productos()
                    print(f"‚úÖ {len(productos)} productos")
                    total_agregados += len(productos)
                else:
                    print(f"‚ö†Ô∏è Sin resultados")
                
                # Guardar cada 5 b√∫squedas
                if idx % 5 == 0:
                    cache_manager.guardar_cache()
                    print(f"   üíæ Cach√© guardado")
                
                sleep(0.3)  # Pausa para no saturar la API
                
            except Exception as e:
                print(f"‚ùå Error: {e}")
                continue
        
        cache_manager.guardar_cache()
        print("")
        print("="*80)
        print(f"‚úÖ AUTOPRECARGA COMPLETADA: ~{total_agregados} productos guardados")
        print("="*80)
        print("")
    
    def buscar_productos(self, query: str) -> List[Dict]:
        """
        B√∫squeda R√ÅPIDA en Carrefour con cach√©
        1. Busca en cach√© primero (instant√°neo)
        2. Si cach√© completo (> 500 productos), usar solo cach√©
        3. Si no, buscar en web
        """
        
        # Inicializar variable para evitar error de scope
        productos_cache = []
        
        # Si estamos precargando, saltar toda la l√≥gica de cach√© y autoprecarga
        if not self._precargando:
            # PASO 1: Buscar en cach√©
            print(f"[Carrefour] Buscando '{query}'...")
            productos_cache = cache_manager.buscar_producto('carrefour', query)
            print(f"üíæ {len(productos_cache)} productos en cach√©")
            
            # Si el cach√© tiene un cat√°logo completo, confiar en √©l
            total_en_cache = len(cache_manager.cache['productos'].get('carrefour', {}))
            print(f"üíæ Total productos en cach√© de Carrefour: {total_en_cache}")
            
            # Si el cach√© est√° vac√≠o o muy peque√±o, hacer autoprecarga (evitar recursi√≥n)
            if total_en_cache < 100:
                print(f"‚ö†Ô∏è  Cach√© insuficiente ({total_en_cache} productos), iniciando autoprecarga...")
                self._precargando = True
                self._auto_precargar()
                self._precargando = False
                # Volver a buscar despu√©s de precargar
                productos_cache = cache_manager.buscar_producto('carrefour', query)
                total_en_cache = len(cache_manager.cache['productos'].get('carrefour', {}))
            
            if total_en_cache > 500:
                print(f"‚ö° Usando cach√© completo precargado (b√∫squeda instant√°nea)")
                return self._formatear_productos_cache(productos_cache)
            
            # Fallback: buscar en web si cach√© incompleto
            if len(productos_cache) >= 20:
                print(f"‚ö° Suficientes en cach√©, retornando")
                return self._formatear_productos_cache(productos_cache)
        
        # PASO 2: Buscar en web
        print(f"üåê Buscando m√°s en web...")
        productos_dict = {}  # Usar dict para evitar duplicados por nombre
        
        try:
            # Preparar queries: palabras en orden inverso para multi-palabra
            palabras = query.strip().split()
            queries_a_buscar = []
            
            if len(palabras) > 1:
                # B√∫squeda multi-palabra: orden inverso (espec√≠fico primero)
                queries_a_buscar.extend(reversed(palabras))
            else:
                queries_a_buscar.append(query.strip())
            
            print(f"[Carrefour] B√∫squeda r√°pida: '{query}'")
            
            # Buscar con cada query (SIN iterar categor√≠as)
            for query_api in queries_a_buscar:
                try:
                    # B√∫squeda DIRECTA sin filtro de categor√≠a = M√ÅS R√ÅPIDO
                    params = {
                        'ft': query_api,
                        '_from': 0,
                        '_to': 19  # Solo 20 productos por query
                    }
                    
                    response = self.session.get(
                        self.api_search_url, 
                        params=params, 
                        timeout=5  # Timeout m√°s corto
                    )
                    
                    if response.status_code not in [200, 206]:
                        continue
                    
                    productos_json = response.json()
                    
                    if not productos_json:
                        continue
                    
                    # Procesar productos
                    for producto_vtex in productos_json:
                        try:
                            nombre = producto_vtex.get('productName', '')
                            if not nombre or nombre in productos_dict:
                                continue
                            
                            items = producto_vtex.get('items', [])
                            if not items:
                                continue
                            
                            sellers = items[0].get('sellers', [])
                            if not sellers:
                                continue
                            
                            precio = sellers[0].get('commertialOffer', {}).get('Price', 0)
                            
                            # Imagen
                            imagen_url = None
                            images = items[0].get('images', [])
                            if images:
                                imagen_url = images[0].get('imageUrl', '')
                            
                            if precio > 0:
                                producto_url = f"{self.base_url}/{producto_vtex.get('linkText', '')}/p"
                                productos_dict[nombre] = {
                                    'nombre': nombre.strip(),
                                    'precio': float(precio),
                                    'supermercado': self.supermercado_nombre,
                                    'url': producto_url,
                                    'imagen': imagen_url
                                }
                                
                                # Guardar en cach√©
                                cache_manager.agregar_producto(
                                    supermercado='carrefour',
                                    nombre=nombre.strip(),
                                    categoria='',  # Carrefour no usa categor√≠as en este scraper
                                    precio=float(precio),
                                    url=producto_url,
                                    imagen_url=imagen_url
                                )
                        
                        except Exception:
                            continue
                
                except Exception:
                    continue
            
        except Exception as e:
            print(f"[Carrefour] Error en b√∫squeda: {e}")
        
        # Guardar cach√©
        cache_manager.guardar_cache()
        
        productos_lista = list(productos_dict.values())
        print(f"‚úÖ Scraping completado: {len(productos_lista)} productos nuevos")
        
        # COMBINAR con cach√©
        if productos_cache:
            print(f"   Combinando con {len(productos_cache)} del cach√©...")
            nombres_scraping = {p['nombre'].lower() for p in productos_lista}
            
            for prod_cache in productos_cache:
                if prod_cache['nombre'].lower() not in nombres_scraping:
                    productos_lista.append({
                        'nombre': prod_cache['nombre'],
                        'precio': prod_cache['precio'],
                        'supermercado': self.supermercado_nombre,
                        'imagen': prod_cache.get('imagen_url'),
                        'url': prod_cache['url']
                    })
        
        print(f"‚úÖ Total retornados: {len(productos_lista)}")
        return productos_lista
    
    def _formatear_productos_cache(self, productos_cache):
        """Convierte productos del cach√© al formato esperado"""
        productos_formateados = []
        
        for prod in productos_cache:
            productos_formateados.append({
                'nombre': prod['nombre'],
                'precio': prod['precio'],
                'supermercado': self.supermercado_nombre,
                'imagen': prod.get('imagen_url'),
                'url': prod['url']
            })
        
        return productos_formateados